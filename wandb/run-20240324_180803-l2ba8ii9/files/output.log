Max Length for sentence = 44
768 0.1 MultiHeadAttentionBlock(
  (w_q): Linear(in_features=768, out_features=768, bias=True)
  (w_k): Linear(in_features=768, out_features=768, bias=True)
  (w_v): Linear(in_features=768, out_features=768, bias=True)
  (w_o): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
768 0.1 MultiHeadAttentionBlock(
  (w_q): Linear(in_features=768, out_features=768, bias=True)
  (w_k): Linear(in_features=768, out_features=768, bias=True)
  (w_v): Linear(in_features=768, out_features=768, bias=True)
  (w_o): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
768 0.1 MultiHeadAttentionBlock(
  (w_q): Linear(in_features=768, out_features=768, bias=True)
  (w_k): Linear(in_features=768, out_features=768, bias=True)
  (w_v): Linear(in_features=768, out_features=768, bias=True)
  (w_o): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
Traceback (most recent call last):
  File "c:\Shaurya\Longformer2\LongformerCoLA\train.py", line 156, in <module>
    train_model(config)
  File "c:\Shaurya\Longformer2\LongformerCoLA\train.py", line 93, in train_model
    model = get_model(config, tokenizer.get_vocab_size()).to(device)
  File "c:\Shaurya\Longformer2\LongformerCoLA\train.py", line 70, in get_model
    model = build_longformer(
  File "c:\Shaurya\Longformer2\LongformerCoLA\model.py", line 235, in build_longformer
    encoder = Encoder(d_model, nn.ModuleList(encoder_blocks),  len(encoder_blocks),)
  File "c:\Shaurya\Longformer2\LongformerCoLA\model.py", line 185, in __init__
    self.layers = nn.ModuleList([layer_class(features) for _ in range(num_layers)])
  File "c:\Shaurya\Longformer2\LongformerCoLA\model.py", line 185, in <listcomp>
    self.layers = nn.ModuleList([layer_class(features) for _ in range(num_layers)])
  File "C:\Users\Shaurya\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Shaurya\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Shaurya\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 374, in _forward_unimplemented
    raise NotImplementedError(f"Module [{type(self).__name__}] is missing the required \"forward\" function")
NotImplementedError: Module [ModuleList] is missing the required "forward" function